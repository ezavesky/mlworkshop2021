{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Pinnacle python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacle.service.notebook_api import NotebookApi\n",
    "api = NotebookApi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m \u001b[1m To access any other pinnacle usecase, please launch the jupyter notebook from the particular usecase or to gain access to all participating usecases, launch the jupyter notebook from the home page.  \u001b[0m\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "usecases=api.get_usecases()\n",
    "print(usecases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pinnacle API to fetch datasets for usecase name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User can fetch dataset and store in user directory in notebook for a specific use case using the use case name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m \u001b[1m To access any other pinnacle usecase, please launch the jupyter notebook from the particular usecase or to gain access to all participating usecases, launch the jupyter notebook from the home page.  \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# usecase_name = \"sample usecase\"\n",
    "api.create_workspace_usecase(\"f29e33307cb04960a6697d713b0053a8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pinnacle API to upload experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User can upload experiments and share them with other Pinnacle users!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define the `name` for your experiment and then give it a short description, `desc`. These two parameters are required for uploading your experiment. Optionally, you can specify `pathname` - the experiment's directory that contains the artifacts, which you'd like to upload. By default, `pathname` is defined as the current working directory, `~/notebooks`: the one you see in *File Browser* on the left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This functionality is reserved for notebook instances at the **experiment level** only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Hello, World!\"\n",
    "desc = \"My first Pinnacle experiment\"\n",
    "\n",
    "api.upload_experiment(name, desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that, when it's time to propagate new changes to an experiment that's already been shared, the user will need to execute `.upload_experiment()` again so that changes are visible to those whom the user have shared his or her experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLFlow Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What do we track?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.mlflow.org/docs/latest/tracking.html\n",
    "- **Code Version**: Git commit hash used for the run (if it was run from an MLflow Project)\n",
    "- **Start & End Time**: Start and end time of the run\n",
    "- **Source**: Name of the file to launch the run, or the project name and entry point for the run if run from an MLflow Project.\n",
    "- **Parameters**: Key-value input parameters.<br>\n",
    "    `mlflow.log_param(\"Train alpha\", alpha)`\n",
    "        \n",
    "- **Metrics**: Key-value metrics, where the value is numeric (can be updated over the run)<br>\n",
    "    `mlflow.log_metric(\"Train rmse\", rmse)`\n",
    "    \n",
    "- **Artifacts**: Output files in any format.\n",
    "\n",
    "##### Note \n",
    "* Please refer to the notebooks in `examples/MLFLOW` for more in-depth examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit Model to Pinnacle from model file. run the code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters:\n",
    "\n",
    "`model_name`           : Provide a name for the model <br>\n",
    "`model_directory`      : Provide directory path which contains model file and usecase metadata<br>\n",
    "`run_id`               : Provide run id of the experiment that the model is based on <br>\n",
    "\n",
    "Note:\n",
    "* To obtain model_directory path, right click the directory and select copy path option.\n",
    "* To obtain run_id run:  run.info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacle.service.notebook_api import NotebookApi\n",
    "api = NotebookApi()\n",
    "\n",
    "model_directory = '' # 'Model_folder'\n",
    "model_name = ''      # 'Model_name'\n",
    "run_id = ''          # 'c922217f48934968a24b45f19eb619b6'\n",
    "\n",
    "api.upload_mlflow_model(model_directory=model_directory,\n",
    "model_name=model_name,\n",
    "run_id = run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How MLFlow is integrated to Pinnacle:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When user logs the model in the mlflow, user model will be automatically packaged in to the mlflow tracking server with the requirements in the MLFlow project format. please follow the below link to understand the mlflow packaging format. https://www.mlflow.org/docs/latest/models.html\n",
    "- Once the mlflow model is submitted to pinnacle, Model Executor will download the mlflow model from the tracking server and make prediction using mlflow model predict cli tool. It will create prediction json and executor will internally handle the json and submit the model prediction in pinnacle csv format.\n",
    "\n",
    "Note\n",
    "- MLFlow and Pinnacle integration will handle model run and deployment internally as per pinnacle standard.\n",
    "- User should encapsulate the preprocessing steps in the model while logging it, since built in mlflow model prediction method expects same input as model trained. Look at examples/MLFLOW for more in-depth examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To submit prediction file run below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacle.service.notebook_api import NotebookApi\n",
    "api = NotebookApi()\n",
    "\n",
    "model_name = ''\n",
    "prediction_file_name = ''\n",
    "model_directory = ''\n",
    "api.upload_model_prediction(model_name=model_name, \n",
    "                            prediction_file_name=prediction_file_name,\n",
    "                           model_directory=model_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To submit model and its artifacts run below code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before submitting the model, make sure the model and its artifacts are kept inside the same directory. This will act as the model directory.\n",
    "\n",
    "Parameters: \n",
    "\n",
    "`model_directory` : Provide directory path which contains model and its artifacts. <br>\n",
    "`model_name`: Provide a name for the model submitted to pinnacle <br>\n",
    "`model_file_name`: Provide the file name of the model script <br>\n",
    "`train_command`   : Training command as per the model lanuguage Eg : for python model - \"python sample_model.py TRAIN\", for R model - \"Rscript sample_model.R -t\" <br>\n",
    "`run_command`     : Run command as per the model lanuguage Eg : for python model - \"python sample_model.py EXECUTE\", for R Model - \"Rscript sample_model.R -j\" <br>\n",
    "\n",
    "Note:\n",
    "\n",
    "* To obtain model_directory path, right click the directory and select copy path option.\n",
    "* SDK currently supports upload of python and R models only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run below cell to submit a python script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacle.service.notebook_api import NotebookApi\n",
    "api = NotebookApi()\n",
    "model_directory = ''\n",
    "model_name = ''\n",
    "model_file_name = ''\n",
    "train_command = 'python {} TRAIN'.format(model_file_name)\n",
    "run_command = 'python {} EXECUTE'.format(model_file_name)\n",
    "api.upload_model(model_directory = model_directory,\n",
    "                 model_name=model_name,\n",
    "                 model_file_name = model_file_name,\n",
    "                train_command=train_command,\n",
    "                run_command=run_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run below cell to submit a R script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacle.service.notebook_api import NotebookApi\n",
    "api = NotebookApi()\n",
    "model_directory = ''\n",
    "model_name = ''\n",
    "model_file_name = ''\n",
    "train_command = 'Rscript {} -t'.format(model_file_name)\n",
    "run_command = 'Rscript {} -j'.format(model_file_name)\n",
    "api.upload_model(model_directory = model_directory,\n",
    "                 model_name=model_name,\n",
    "                 model_file_name = model_file_name,\n",
    "                train_command=train_command,\n",
    "                run_command=run_command)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
